"""
æ— å”¤é†’è¯æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ä¸»ç¨‹åº
é›†æˆè¯­éŸ³è¯†åˆ«ã€æ„å›¾ç†è§£ã€è¯­éŸ³åˆæˆå’Œè®¾å¤‡æ§åˆ¶
"""
import sys
import time
import traceback
import threading
import queue
from audio_interface import AudioInterface
from speech_handler import SpeechHandler
from model_handler import ModelHandler
from mqtt_client import MQTTClient
from conversation_manager import ConversationManager
from device_state import DeviceState
from context_manager import ContextManager

# å…¨å±€é˜Ÿåˆ—ï¼Œç”¨äºå­˜å‚¨æ•è·çš„éŸ³é¢‘ç‰‡æ®µ
audio_queue = queue.Queue()

def listen_worker(audio_interface):
    """
    ç›‘å¬çº¿ç¨‹å·¥ä½œå‡½æ•°ï¼šæŒç»­ç›‘å¬å¹¶å°†éŸ³é¢‘æ”¾å…¥é˜Ÿåˆ—
    """
    try:
        print("[*] ç›‘å¬çº¿ç¨‹å·²å¯åŠ¨")
        for audio_data in audio_interface.listen_for_speech():
            audio_queue.put(audio_data)
    except Exception as e:
        print(f"[!] ç›‘å¬çº¿ç¨‹é”™è¯¯: {e}")

def main():
    print("=" * 60)
    print("æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ (å…¨åŒå·¥ç‰ˆ)")
    print("=" * 60)
    print("åˆå§‹åŒ–ç³»ç»Ÿæ¨¡å—...")

    # 1. åˆå§‹åŒ–æ¨¡å—
    try:
        # è¯­éŸ³æ¥å£
        audio = AudioInterface(energy_threshold=30, silence_limit=1.0)
        
        # è¯­éŸ³å¤„ç† (STT/TTS)
        speech = SpeechHandler()
        
        # å¯¹è¯ç®¡ç†
        conversation_manager = ConversationManager(max_history=10)
        
        # è®¾å¤‡çŠ¶æ€
        device_state = DeviceState()
        
        # ä¸Šä¸‹æ–‡ç®¡ç†
        context_manager = ContextManager(conversation_manager, device_state)
        
        # æ¨¡å‹å¤„ç† (LLM)
        model = ModelHandler(model_name="qwen2.5:7b")
        
        # MQTT å®¢æˆ·ç«¯
        mqtt = MQTTClient()
        mqtt_available = mqtt.connect()
        if not mqtt_available:
            print("âš  MQTT è¿æ¥å¤±è´¥ï¼Œå°†æ— æ³•æ§åˆ¶è®¾å¤‡")
            
    except Exception as e:
        print(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        traceback.print_exc()
        return

    print("\nâœ“ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    print("æ­£åœ¨å¯åŠ¨ç›‘å¬... (è¯·è¯´è¯)")
    print("-" * 60)

    # å¯åŠ¨éŸ³é¢‘æµ
    audio.start_stream()
    
    # å¯åŠ¨ç›‘å¬çº¿ç¨‹
    listener_thread = threading.Thread(target=listen_worker, args=(audio,), daemon=True)
    listener_thread.start()
    
    # æ´»è·ƒçŠ¶æ€ç®¡ç†
    last_interaction_time = 0
    ACTIVE_WINDOW = 30 # 30ç§’å†…å¤„äºæ´»è·ƒçŠ¶æ€ï¼Œæ›´å®¹æ˜“è§¦å‘
    
    try:
        # ä¸»å¾ªç¯ï¼šå¤„ç†é˜Ÿåˆ—ä¸­çš„éŸ³é¢‘
        while True:
            # ä»é˜Ÿåˆ—è·å–éŸ³é¢‘æ•°æ®ï¼ˆé˜»å¡ç­‰å¾…ï¼‰
            try:
                # è®¾ç½®è¶…æ—¶ï¼Œä»¥ä¾¿èƒ½å¤Ÿå“åº”KeyboardInterrupt
                audio_data = audio_queue.get(timeout=1.0)
            except queue.Empty:
                continue
                
            # 1. è¯­éŸ³è½¬æ–‡å­—
            print(">>> æ­£åœ¨è¯†åˆ«...")
            text = speech.speech_to_text(audio_data)
            
            if not text or len(text.strip()) == 0:
                print("--- (æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³)")
                continue
                
            print(f"ç”¨æˆ·è¯´: {text}")
            
            # 2. ä¸Šä¸‹æ–‡å¢å¼ºä¸æ„å›¾åˆ†æ
            # å¤„ç†ä»£è¯
            resolved_text = text
            resolved = context_manager.resolve_pronoun(text)
            if resolved:
                print(f"ğŸ’¡ æŒ‡ä»£æ¶ˆè§£: {text} -> {resolved}")
                resolved_text = resolved
            
            # è·å–ä¸Šä¸‹æ–‡
            context = conversation_manager.get_full_context()
            
            # å¦‚æœå¤„äºæ´»è·ƒçª—å£ï¼Œæç¤ºæ¨¡å‹æ›´å€¾å‘äºè®¤ä¸ºæ˜¯å¯¹è¯
            is_active = (time.time() - last_interaction_time) < ACTIVE_WINDOW
            if is_active:
                print("[*] å¤„äºæ´»è·ƒäº¤äº’æ¨¡å¼")
            
            print(">>> åˆ†ææ„å›¾(å«çº é”™)...")
            # ä½¿ç”¨è§£æåçš„æ–‡æœ¬è¿›è¡Œæ„å›¾åˆ†æ
            analysis = model.analyze_intent(resolved_text, context)
            intent = analysis.get("intent", "ignore")
            corrected_text = analysis.get("corrected_text", resolved_text)
            
            # å¦‚æœå‘ç”Ÿäº†çº é”™
            if corrected_text != resolved_text:
                 print(f"ğŸ’¡ LLMçº é”™: {resolved_text} -> {corrected_text}")
                 resolved_text = corrected_text
            
            print(f"æ„å›¾åˆ¤åˆ«: {intent} (ç†ç”±: {analysis.get('reason', 'æ— ')})")
            
            # 3. æ ¹æ®æ„å›¾å¤„ç†
            response_text = ""
            should_reply = False
            
            if intent == "ignore":
                # å¦‚æœéå¸¸æ´»è·ƒä¸”æ–‡æœ¬è¾ƒé•¿ï¼Œå¯èƒ½è¯¯åˆ¤ï¼Œæˆ–è€…æ˜¯é—²èŠ
                if is_active and len(text) > 3:
                     # äºŒæ¬¡ç¡®è®¤ï¼Œæˆ–è€…ç›´æ¥å½“åšchat
                     # æ­¤æ—¶æˆ‘ä»¬å¯ä»¥å‡è®¾æ˜¯Chatï¼Œå› ä¸ºå¤„äºæ´»è·ƒå¯¹è¯ä¸­
                     intent = "chat"
                     print(">>> æ´»è·ƒæ¨¡å¼ä¸‹å¿½ç•¥åˆ¤æ–­ä¿®æ­£ä¸º Chat")
                else:
                    print("--- å¿½ç•¥æ­¤æ¶ˆæ¯")
                    continue
            
            if intent == "command":
                # å¤„ç†æŒ‡ä»¤
                print(">>> è¯†åˆ«æŒ‡ä»¤è¯¦æƒ…...")
                # ç»“åˆè®¾å¤‡çŠ¶æ€
                states = device_state.get_state_summary()
                # ä½¿ç”¨è§£æåçš„æ–‡æœ¬
                cmd_result = model.recognize_command(resolved_text, context, states)
                
                if cmd_result.get("type") != "none":
                    formatted_cmd = model.format_command_message(cmd_result)
                    print(f"æ‰§è¡ŒæŒ‡ä»¤: {formatted_cmd}")
                    
                    if mqtt_available:
                        success = mqtt.send_command(cmd_result)
                        if success:
                            device_state.update_state(cmd_result)
                            response_text = f"å¥½çš„ï¼Œ{formatted_cmd}"
                        else:
                            response_text = f"æŠ±æ­‰ï¼Œ{formatted_cmd}å¤±è´¥äº†"
                    else:
                        response_text = f"æˆ‘æ˜ç™½äº†ï¼Œ{formatted_cmd}ï¼Œä½†æ˜¯MQTTæœªè¿æ¥ã€‚"
                    
                    should_reply = True
                    # è®°å½•æŒ‡ä»¤åˆ°å†å²
                    conversation_manager.add_message("user", resolved_text)
                    conversation_manager.add_message("assistant", response_text, cmd_result)
                else:
                    response_text = "æŠ±æ­‰ï¼Œæˆ‘æ²¡å¬æ‡‚å…·ä½“çš„æŒ‡ä»¤ã€‚"
                    should_reply = True
            
            elif intent == "chat":
                # å¤„ç†é—²èŠ
                print(">>> ç”Ÿæˆå›å¤...")
                conversation_manager.add_message("user", resolved_text)
                response_text = model.generate_chat_response(resolved_text, context)
                conversation_manager.add_message("assistant", response_text)
                print(f"åŠ©æ‰‹è¯´: {response_text}")
                should_reply = True

            # 4. è¯­éŸ³å›å¤
            if should_reply and response_text:
                # æ›´æ–°æ´»è·ƒæ—¶é—´
                last_interaction_time = time.time()
                
                print(f">>> æ­£åœ¨æ’­æŠ¥: {response_text}")
                
                # æš‚åœç›‘å¬ï¼ˆé˜²æ­¢å¬åˆ°è‡ªå·±ï¼‰
                audio.pause()
                
                tts_file = speech.text_to_speech(response_text)
                if tts_file:
                    speech.play_audio_file(tts_file)
                    try:
                        import os
                        os.remove(tts_file)
                    except:
                        pass
                
                # æ¢å¤ç›‘å¬
                audio.resume()
                print(">>> æ¢å¤ç›‘å¬")


    except KeyboardInterrupt:
        print("\nåœæ­¢ç›‘å¬")
    except Exception as e:
        print(f"å‘ç”Ÿé”™è¯¯: {e}")
        traceback.print_exc()
    finally:
        audio.close()
        if mqtt_available:
            mqtt.disconnect()

if __name__ == "__main__":
    main()
